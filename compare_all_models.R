# ===============================================================
# ğŸ”¹ 1. CÃ i Ä‘áº·t & náº¡p thÆ° viá»‡n
# ===============================================================
if (!require(tidyverse)) install.packages("tidyverse")
if (!require(caret)) install.packages("caret")
if (!require(glmnet)) install.packages("glmnet")
# if (!require(Metrics)) install.packages("Metrics") # KhÃ´ng cáº§n thiáº¿t náº¿u dÃ¹ng caret
if (!require(xgboost)) install.packages("xgboost")
if (!require(ggplot2)) install.packages("ggplot2")
if (!require(gridExtra)) install.packages("gridExtra")

library(tidyverse)
library(caret)
library(glmnet)
library(xgboost)
library(ggplot2)
library(gridExtra)

# =Caret xung Ä‘á»™t vá»›i Metrics á»Ÿ hÃ m R2, nÃªn chÃºng ta sáº½ chá»‰ dÃ¹ng caret
# library(Metrics) 

# ===============================================================
# ğŸ”¹ 2. Äá»c vÃ  xá»­ lÃ½ dá»¯ liá»‡u
# ===============================================================
data <- read.csv("student_performance_clean.csv")

# Chuáº©n hÃ³a dá»¯ liá»‡u 'internet' (yes/no -> 1/0)
data$internet <- ifelse(data$internet == "yes", 1, 0)

# XÃ¡c Ä‘á»‹nh features (X) vÃ  target (y)
X <- data %>% select(studytime, failures, internet, G1, G2)
y <- data$G3

# Chia dá»¯ liá»‡u train/test (80/20)
set.seed(42) # Äá»ƒ Ä‘áº£m báº£o káº¿t quáº£ cÃ³ thá»ƒ láº·p láº¡i
train_index <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[train_index, ]
X_test  <- X[-train_index, ]
y_train <- y[train_index]
y_test  <- y[-train_index]

# ===============================================================
# ğŸ”¹ 3. Linear Regression (Há»“i quy tuyáº¿n tÃ­nh)
# ===============================================================
model_linear <- lm(y_train ~ ., data = X_train)
pred_linear <- predict(model_linear, newdata = X_test)

# FIX: DÃ¹ng hÃ m cá»§a caret: RMSE(pred, obs) vÃ  R2(pred, obs)
rmse_linear <- RMSE(pred_linear, y_test)
r2_linear <- R2(pred_linear, y_test)

# ===============================================================
# ğŸ”¹ 4. Ridge Regression (alpha = 0)
# ===============================================================
X_train_mat <- as.matrix(X_train)
X_test_mat  <- as.matrix(X_test)

ridge_model <- cv.glmnet(X_train_mat, y_train, alpha = 0)
# FIX: ThÃªm as.vector() Ä‘á»ƒ chuyá»ƒn káº¿t quáº£ tá»« matrix vá» vector
ridge_pred <- as.vector(predict(ridge_model, s = ridge_model$lambda.min, newx = X_test_mat))

rmse_ridge <- RMSE(ridge_pred, y_test)
r2_ridge <- R2(ridge_pred, y_test)

# ===============================================================
# ğŸ”¹ 5. Lasso Regression (alpha = 1)
# ===============================================================
lasso_model <- cv.glmnet(X_train_mat, y_train, alpha = 1)
# FIX: ThÃªm as.vector()
lasso_pred <- as.vector(predict(lasso_model, s = lasso_model$lambda.min, newx = X_test_mat))

rmse_lasso <- RMSE(lasso_pred, y_test)
r2_lasso <- R2(lasso_pred, y_test)

# ===============================================================
# ğŸ”¹ 6. Polynomial Regression (báº­c 2)
# ===============================================================

# FIX: Sá»­a lá»—i Data Leakage
# Chá»‰ táº¡o biáº¿n báº­c 2 trÃªn táº­p train vÃ  test má»™t cÃ¡ch riÃªng biá»‡t
X_train_poly <- X_train %>% mutate(
  studytime2 = studytime^2,
  failures2 = failures^2,
  G1_2 = G1^2,
  G2_2 = G2^2
)

X_test_poly <- X_test %>% mutate(
  studytime2 = studytime^2,
  failures2 = failures^2,
  G1_2 = G1^2,
  G2_2 = G2^2
)

model_poly <- lm(y_train ~ ., data = X_train_poly)
pred_poly <- predict(model_poly, newdata = X_test_poly)

rmse_poly <- RMSE(pred_poly, y_test)
r2_poly <- R2(pred_poly, y_test)

# ===============================================================
# ğŸ”¹ 7. XGBoost Regression
# (Giá»¯ láº¡i Ä‘á»ƒ so sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh linear theo yÃªu cáº§u dá»± Ã¡n)
# ===============================================================
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
dtest  <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)

params <- list(objective = "reg:squarederror", eta = 0.1, max_depth = 5)
xgb_model <- xgb.train(params = params, data = dtrain, nrounds = 100, verbose = 0)

xgb_pred <- predict(xgb_model, dtest)

rmse_xgb <- RMSE(xgb_pred, y_test)
r2_xgb <- R2(xgb_pred, y_test)

# ===============================================================
# ğŸ”¹ 8. Tá»•ng há»£p káº¿t quáº£
# ===============================================================
results <- data.frame(
  Model = c("Linear", "Ridge", "Lasso", "Polynomial", "XGBoost"),
  RMSE = c(rmse_linear, rmse_ridge, rmse_lasso, rmse_poly, rmse_xgb),
  R2 = c(r2_linear, r2_ridge, r2_lasso, r2_poly, r2_xgb)
)

print(results)

# ===============================================================
# ğŸ”¹ 9. Biá»ƒu Ä‘á»“ so sÃ¡nh
# ===============================================================

# FIX: DÃ¹ng reorder() Ä‘á»ƒ tá»± Ä‘á»™ng sáº¯p xáº¿p cá»™t theo giÃ¡ trá»‹
# reorder(Model, -R2) -> Sáº¯p xáº¿p theo R2 giáº£m dáº§n
p1 <- ggplot(results, aes(x = reorder(Model, -R2), y = R2, fill = Model)) +
  geom_bar(stat = "identity", width = 0.6) +
  theme_minimal(base_size = 14) +
  ggtitle("So sÃ¡nh RÂ² giá»¯a cÃ¡c mÃ´ hÃ¬nh") +
  ylab("RÂ² (CÃ ng cao cÃ ng tá»‘t)") +
  xlab("MÃ´ hÃ¬nh") +
  geom_text(aes(label = round(R2, 3)), vjust = -0.5, size = 5) +
  scale_fill_brewer(palette = "Set2") +
  theme(legend.position = "none") # Bá» chÃº thÃ­ch vÃ¬ Ä‘Ã£ cÃ³ tÃªn á»Ÿ trá»¥c X

# reorder(Model, RMSE) -> Sáº¯p xáº¿p theo RMSE tÄƒng dáº§n
p2 <- ggplot(results, aes(x = reorder(Model, RMSE), y = RMSE, fill = Model)) +
  geom_bar(stat = "identity", width = 0.6) +
  theme_minimal(base_size = 14) +
  ggtitle("So sÃ¡nh RMSE giá»¯a cÃ¡c mÃ´ hÃ¬nh") +
  ylab("RMSE (CÃ ng tháº¥p cÃ ng tá»‘t)") +
  xlab("MÃ´ hÃ¬nh") +
  geom_text(aes(label = round(RMSE, 3)), vjust = -0.5, size = 5) +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "none")

# Sáº¯p xáº¿p 2 biá»ƒu Ä‘á»“ cáº¡nh nhau
grid.arrange(p1, p2, ncol = 2)

# ===============================================================
# ğŸ”¹ 10. LÆ°u hÃ¬nh ra file
# ===============================================================
# Gá»™p 2 biá»ƒu Ä‘á»“ vÃ o 1 file áº£nh
combined_plot <- grid.arrange(p1, p2, ncol = 2)
ggsave("model_comparison.png", plot = combined_plot, width = 16, height = 7, dpi = 300)